#!/usr/bin/perl
#
# This will automatically start the Anvil!'s cluster stack on boot.
# 
# If you don't know what an Anvil! is, see:
# - https://alteeve.ca/w/AN!Cluster_Tutorial_2
#
# Exit Codes:
# 0  - OK
# 1  - Couldn't find peer's host name.
# 2  - Daemon status returned unhandled return code.
# 3  - This node is not healthy, but the peer node is healthy. Exiting to let
#      the peer's 'safe_anvil_start' boot the servers.
# 4  - Both nodes have either failed services, badly mounted cluster
#      filesystems or a combination of the two.
# 5  - Local node is not in a failed state, but it timed out waiting to become
#      healthy.
# 6  - Failed to connect to my peer within the timeout. To proceed would risk a
#      fence loop.
# 
# Bugs:
# - It would seem that, in some case (which I don't yet have a reproducer for),
#   there is a timing-based conflict starting cman/rgmanager. When this
#   happens, cman or drbd (via rgmanager failing to start) will lead to a fence
#   of the effected peer.
# - If /shared's dm device differs on the two nodes, VMs won't start is both
#   nodes will think the other is not healthy.
#
# TODO:
# - Check the health status file and do not initiate start up until the health
#   is "OK" on at least one node. When deciding which node to power a server
#   on, check if one node is "warning" and do not use it if so.
#

use strict;
use warnings;
use IO::Handle;
use File::Basename;

my $conf =  {
	cluster		=>	{
		name		=>	"",
	},
	daemons		=>	{
		cman		=>	"/etc/init.d/cman",
		rgmanager	=>	"/etc/init.d/rgmanager",
	},
	debug		=>	2,
	drbd		=>	{},
	failoverdomain	=>	{},
	lvs		=>	{},
	nodes		=>	{
		me		=>	{
			clusterfs	=>	{},
			daemon		=>	{},
			healthy		=>	0,	# 0 == not ready, 1 == healthy, 2 == fatal error, won't run Servers.
			hostname	=>	"",
			mounts		=>	{},
			short_name	=>	"",
		},
		peer		=>	{
			clusterfs	=>	{},
			daemon		=>	{},
			healthy		=>	0,
			hostname	=>	"",
			is_up		=>	0,
			mounts		=>	{},
			short_name	=>	"",
		}
	},
	path		=>	{
		clustat		=>	"/usr/sbin/clustat",
		cluster_conf	=>	"/etc/cluster/cluster.conf",
		clusvcadm	=>	"/usr/sbin/clusvcadm",
		df		=>	"/bin/df",
		drbdadm		=>	"/sbin/drbdadm",
		echo		=>	"/bin/echo",
		hostname	=>	"/bin/hostname",
		ls		=>	"/bin/ls",
		lvs		=>	"/sbin/lvs",
		ssh		=>	"/usr/bin/ssh",
	},
	services	=>	{},
	timeouts	=>	{
		wait_for_drbd_sync	=>	300,	# Roughly 5 minutes.
		wait_for_node_health	=>	300,	# Roughly 5 minutes.
		wait_for_peer		=>	3600,	# Roughly 1 hour.
	},
	vms		=>	{},
};

print "\n-=] Safe Anvil! Start is now running.\n" if $conf->{debug} > 0;
read_hostname($conf);
read_cluster_conf($conf);
### TODO: Provide an optional max wait time where the wait ends and the peer
###       is fenced so that start up can complete.
print " - Wait up to: [$conf->{timeouts}{wait_for_peer}] seconds to connect to my peer.\n" if $conf->{debug} == 1;
print " - ." if $conf->{debug} == 1;
for (0..$conf->{timeouts}{wait_for_peer})
{
	$conf->{nodes}{peer}{is_up} = check_peer_connection($conf);
	if ($conf->{nodes}{peer}{is_up})
	{
		# Peer is up.
		print " - Peer is up!\n" if $conf->{debug} == 1;
		last;
	}
	else
	{
		# The "peer is up!" message starts with a line-wrap to close
		# this dotted progress bar.
		print ".";
	}
	sleep 1;
};

# If the peer wasn't reachable, then the only safe option is to exit.
if (not $conf->{nodes}{peer}{is_up})
{
	print "Failed to connect to peer within timeout.\n";
	print "Proceeding would risk a fence loop. Exiting.\n";
	exit(6);
}

# Check the state of the daemons.
check_daemons($conf);

# Now the fun starts!
start_daemon_simultaneously($conf, "cman");
sleep 2;	# This may not be needed, but is here just in case a race
		# condition is possible.
start_daemon_simultaneously($conf, "rgmanager");

# Check the health of each node's daemons, clusterfs mounts and services.
check_node_health($conf);

# Watches DRBD to see if both nodes go UpToDate within a reasonable amount of
# time.
wait_for_drbd_sync($conf);

# If I am still alive, I am healthy. Time to start the servers!
start_servers($conf);

# All done.
print __LINE__."; [ DEBUG ] - Finished, exiting.\n" if $conf->{debug} == 2;
print " - Finished, exiting.\n\n" if $conf->{debug} == 1;
exit(0);

###############################################################################
# Here be Functions!                                                          #
###############################################################################

# This gets the list of physical volume(s) backing each logical volume. This is
# needed to check the DRBD connection and disk state when deciding later which
# node to start the server on.
sub get_pvs_under_lv
{
	my ($conf) = @_;
	
	my @pvs;
	my $fh = IO::Handle->new();
	my $sc = "$conf->{path}{lvs} --separator ' ' -o lv_name,vg_name,lv_path,devices";
	print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
	while(<$fh>)
	{
		chomp;
		my $line = $_;
		print __LINE__."; [ DEBUG ] - line: [$line].\n" if $conf->{debug} == 2;
		if ($line =~ / (.*?) (.*?) (\/dev\/.*?) (\/dev\/.*)/)
		{
			my $lv_name = $1;
			my $vg_name = $2;
			my $lv_path = $3;
			my $pvs     = $4;
			# PVs are listed with their starting extend in brackets
			# which we don't care about.
			$pvs =~ s/\(.*?\)//g;
			# If the LV spans PVs, they will be comma-separated.
			$conf->{lvs}{$lv_path}{pvs} = $pvs;
			print __LINE__."; [ DEBUG ] - lvs::${lv_path}::pvs: [$conf->{lvs}{$lv_path}{pvs}].\n" if $conf->{debug} == 2;
		}
	}
	$fh->close();
	
	return(0)
}

# This translates a DRBD resource name to it's block device path.
sub translate_drbd_resource_to_device_path
{
	my ($conf, $resource) = @_;
	print __LINE__."; [ DEBUG ] - translate_drbd_resource_to_device_path(); resource: [$resource]\n" if $conf->{debug} == 2;
	
	# This 'drbdadm' switch is in 'drbdadm hidden-commands'.
	my $device_path = "";
	my $fh          = IO::Handle->new();
	my $sc          = "$conf->{path}{drbdadm} sh-dev $resource";
	print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
	while(<$fh>)
	{
		chomp;
		my $line = $_;
		print __LINE__."; [ DEBUG ] - line: [$line].\n" if $conf->{debug} == 2;
		if ($line =~ /^(\/dev\/.*)/)
		{
			$device_path = $1;
			print __LINE__."; [ DEBUG ] - device_path: [$device_path].\n" if $conf->{debug} == 2;
		}
	}
	$fh->close();
	
	return($device_path);
}

# This reads the current state of DRBD resource. This is used later to help
# decide which node to start a server on.
sub read_drbd_state
{
	my ($conf) = @_;
	
	my $fh = IO::Handle->new();
	my $sc = "/etc/init.d/drbd status";
	print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
	while(<$fh>)
	{
		# I don't care about this output
		chomp;
		my $line = $_;
		next if not $line;
		print __LINE__."; [ DEBUG ] - line: [$line]\n" if $conf->{debug} == 2;
		if ($line =~ /(\d+):(.*?)\s+(.*?)\s+(.*?)\/(.*?)\s+(.*?)\/(.*?)\s/)
		{
			my $minor_number     = $1;
			my $resource_name    = $2;
			my $connection_state = $3;
			my $me_role          = $4;
			my $peer_role        = $5;
			my $me_disk_state    = $6;
			my $peer_disk_state  = $7;
			my ($device_path)    = translate_drbd_resource_to_device_path($conf, $resource_name);
			print __LINE__."; [ DEBUG ] - minor_number: [$minor_number], resource_name: [$resource_name], connection_state: [$connection_state], me_role: [$me_role], peer_role: [$peer_role], me_disk_state: [$me_disk_state], peer_disk_state: [$peer_disk_state], device_path: [$device_path]\n" if $conf->{debug} == 2;
			$conf->{drbd}{$device_path}{minor_number}     = $minor_number;
			$conf->{drbd}{$device_path}{resource_name}    = $resource_name;
			$conf->{drbd}{$device_path}{connection_state} = $connection_state;
			$conf->{drbd}{$device_path}{me}{role}         = $me_role;
			$conf->{drbd}{$device_path}{me}{disk_state}   = $me_disk_state;
			$conf->{drbd}{$device_path}{peer}{role}       = $peer_role;
			$conf->{drbd}{$device_path}{peer}{disk_state} = $peer_disk_state;
			print __LINE__."; [ DEBUG ] - drbd::${device_path}::minor_number:     [$conf->{drbd}{$device_path}{minor_number}]\n" if $conf->{debug} == 2;
			print __LINE__."; [ DEBUG ] - drbd::${device_path}::resource_name:    [$conf->{drbd}{$device_path}{resource_name}]\n" if $conf->{debug} == 2;
			print __LINE__."; [ DEBUG ] - drbd::${device_path}::connection_state: [$conf->{drbd}{$device_path}{connection_state}]\n" if $conf->{debug} == 2;
			print __LINE__."; [ DEBUG ] - drbd::${device_path}::me::role:         [$conf->{drbd}{$device_path}{me}{role}]\n" if $conf->{debug} == 2;
			print __LINE__."; [ DEBUG ] - drbd::${device_path}::me::disk_state:   [$conf->{drbd}{$device_path}{me}{disk_state}]\n" if $conf->{debug} == 2;
			print __LINE__."; [ DEBUG ] - drbd::${device_path}::peer::role:       [$conf->{drbd}{$device_path}{peer}{role}]\n" if $conf->{debug} == 2;
			print __LINE__."; [ DEBUG ] - drbd::${device_path}::peer::disk_state: [$conf->{drbd}{$device_path}{peer}{disk_state}]\n" if $conf->{debug} == 2;
		}
	}
	$fh->close();
	
	return(0);
}

# This starts by calling 'drbdadm adjust all' on both noes, then waiting up to
# the 'wait_for_drbd_sync' seconds for both to go UpToDate.
sub wait_for_drbd_sync
{
	my ($conf) = @_;
	
	# Call 'drbdadm adjust all';
	foreach my $node ("me", "peer")
	{
		next if (($node eq "peer") && ($conf->{nodes}{peer}{healthy} == 2));
		print __LINE__."; [ DEBUG ] - node: [$node]\n" if $conf->{debug} == 2;
		my $fh = IO::Handle->new();
		my $sc = "$conf->{path}{drbdadm} adjust all";
		if ($node eq "peer")
		{
			$sc = "$conf->{path}{ssh} root\@$conf->{nodes}{peer}{hostname} \"$conf->{path}{drbdadm} adjust all\"";
		}
		print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
		open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
		while(<$fh>)
		{
			chomp;
			my $line = $_;
			print __LINE__."; [ DEBUG ] - line: [$line].\n" if $conf->{debug} == 2;
		}
		$fh->close();
	}
	
	# Now loop for up to 'wait_for_drbd_sync' seconds
	my $all_uptodate = 0;
	print __LINE__."; [ DEBUG ] - all_uptodate: [$all_uptodate], timeouts::wait_for_drbd_sync: [$conf->{timeouts}{wait_for_drbd_sync}].\n" if $conf->{debug} == 2;
	print " - Waiting up to: [$conf->{timeouts}{wait_for_drbd_sync}] seconds for DRBD to become 'UpToDate' on both nodes.\n" if $conf->{debug} == 1;
	print " - ." if $conf->{debug} == 1;
	for (0..$conf->{timeouts}{wait_for_drbd_sync})
	{
		read_drbd_state($conf);
		
		$all_uptodate = 1;
		foreach my $device_path (sort {$a cmp $b} keys %{$conf->{drbd}})
		{
			print __LINE__."; [ DEBUG ] - device_path: [$device_path].\n" if $conf->{debug} == 2;
			my $me_role         = $conf->{drbd}{$device_path}{me}{role};
			my $me_disk_state   = $conf->{drbd}{$device_path}{me}{disk_state};
			my $peer_role       = $conf->{drbd}{$device_path}{peer}{role};
			my $peer_disk_state = $conf->{drbd}{$device_path}{peer}{disk_state};
			print __LINE__."; [ DEBUG ] - me_role: [$me_role], me_disk_state: [$me_disk_state], peer_role: [$peer_role], peer_disk_state: [$peer_disk_state].\n" if $conf->{debug} == 2;
			if (lc($me_role) ne "primary")
			{
				$all_uptodate = 0;
				print "." if $conf->{debug} == 1;
				print __LINE__."; [ DEBUG ] - Local DRBD device: [$device_path]'s role is: [$me_role], will wait for it to become 'Primary'.\n" if $conf->{debug} == 2;
			}
			if (lc($peer_role) ne "primary")
			{
				$all_uptodate = 0;
				print "." if $conf->{debug} == 1;
				print __LINE__."; [ DEBUG ] - Peer's DRBD device: [$device_path]'s role is: [$peer_role], will wait for it to become 'Primary'.\n" if $conf->{debug} == 2;
			}
			next if ($conf->{nodes}{peer}{healthy} == 2);
			if (lc($me_disk_state) ne "uptodate")
			{
				$all_uptodate = 0;
				print "." if $conf->{debug} == 1;
				print __LINE__."; [ DEBUG ] - Local DRBD device: [$device_path]'s disk state is: [$me_disk_state], will wait for it to become 'UpToDate'.\n" if $conf->{debug} == 2;
			}
			if (lc($peer_disk_state) ne "uptodate")
			{
				$all_uptodate = 0;
				print "." if $conf->{debug} == 1;
				print __LINE__."; [ DEBUG ] - Peer's DRBD device: [$device_path]'s disk state is: [$peer_disk_state], will wait for it to become 'UpToDate'.\n" if $conf->{debug} == 2;
			}
		}
		if ($all_uptodate)
		{
			print " all UpToDate!\n" if $conf->{debug} == 1;
			last;
		}
		
		sleep 1;
	}
	print __LINE__."; [ DEBUG ] - all_uptodate: [$all_uptodate].\n" if $conf->{debug} == 2;
	if ($all_uptodate)
	{
		if ($conf->{nodes}{peer}{healthy} == 2)
		{
			print __LINE__."; [ DEBUG ] - All DRBD resources online and fully up to date on this node (peer is not healty).\n" if $conf->{debug} == 2;
			print " - All of my resource are Primary and UpToDate.\n" if $conf->{debug} == 1;
		}
		else
		{
			print __LINE__."; [ DEBUG ] - All DRBD resources online and fully up to date.\n" if $conf->{debug} == 2;
			print " - All of DRBD resource on both nodes are Primary and UpToDate.\n" if $conf->{debug} == 1;
		}
	}
	else
	{
		print " - Timeout expired." if $conf->{debug} == 1;
		if ($conf->{nodes}{peer}{healthy} == 2)
		{
			print __LINE__."; [ DEBUG ] - At least one DRBD resource did not become UpToDate or Primary locally (peer is not healthy).\n" if $conf->{debug} == 2;
			print "   - At least one of my DRBD resources is not Primary or UpToDate, peer is unhealthy.\n" if $conf->{debug} == 1;
		}
		else
		{
			print __LINE__."; [ DEBUG ] - At least one DRBD resource did not become UpToDate or Primary on at least one node within timeout period.\n" if $conf->{debug} == 2;
			print "   - All of my resource are UpToDate, but at least one of my peer's resources is not yet Primary or UpToDate.\n" if $conf->{debug} == 1;
		}
	}
	
	return(0);
}

# This reads the XML definition file for a VM. Specifically, we're looki
sub read_vm_definition
{
	my ($conf, $name, $definition) = @_;
	print __LINE__."; [ DEBUG ] - read_vm_definition(); server name: [$name], definition: [$definition]\n" if $conf->{debug} == 2;
	
	my $read_ok = 1;
	if (not -e $definition)
	{
		$read_ok = 0;
		print __LINE__."; [ DEBUG ] - server name: [$name]'s definition: [$definition] file doesn't exist!\n" if $conf->{debug} == 2;
	}
	elsif (not -r $definition)
	{
		$read_ok = 0;
		print __LINE__."; [ DEBUG ] - server name: [$name]'s definition: [$definition] file exists but isn't readable!\n" if $conf->{debug} == 2;
	}
	if ($read_ok)
	{
		my $in_disk = 0;
		my $fh = IO::Handle->new();
		my $sc = "$definition";
		print __LINE__."; [ DEBUG ] - File read: [$sc]\n" if $conf->{debug} == 2;
		open ($fh, "<$sc") or die "Failed to read: [$sc], error was: $!\n";
		while(<$fh>)
		{
			# I don't care about this output
			chomp;
			my $line = $_;
			next if not $line;
			#print __LINE__."; [ DEBUG ] - line: [$line]\n" if $conf->{debug} == 2;
			
			if ($line =~ /<disk .*?device='disk'/)
			{
				# TODO: Make this check that the "inserted" ISO
				# actually exists, and if not, remove the ISO
				# from the definition file as not existing will
				# block boot.
				next if $line =~ /device='cdrom'/;
				$in_disk = 1;
				#print __LINE__."; [ DEBUG ] - Going in_disk: [$in_disk]\n" if $conf->{debug} == 2;
				next;
			}
			if ($in_disk)
			{
				if ($line =~ /<\/disk>/)
				{
					$in_disk = 0;
					#print __LINE__."; [ DEBUG ] - Exiting in_disk: [$in_disk]\n" if $conf->{debug} == 2;
					next;
				}
				if ($line =~ /<source dev='(.*?)'/)
				{
					my $lv_path = $1;
					push @{$conf->{vms}{$name}{lv_path}}, $lv_path;
					print __LINE__."; [ DEBUG ] - Adding lv_path: [$lv_path] to array vms::${name}::lv_path. Array contains: [".@{$conf->{vms}{$name}{lv_path}}."] disk(s).\n" if $conf->{debug} == 2;
				}
			}
		}
		$fh->close();
	}
	
	return($read_ok)
}

# This checks the health of the storage behind each server and decides where to
# boot each server.
sub start_servers
{
	my ($conf) = @_;
	
	# Get a list of PV(s) under each LV.
	get_pvs_under_lv($conf);
	
	# Now decide where to start each server.
	foreach my $name (sort {$a cmp $b} keys %{$conf->{vm}})
	{
		print " - Starting server: [$name] (current state: [$conf->{vm}{$name}{'state'}], current host: [$conf->{vm}{$name}{host}]).\n" if $conf->{debug} == 1;
		print __LINE__."; [ DEBUG ] - Reading server: [$name]'s definition file: [$conf->{vm}{$name}{definition}].\n" if $conf->{debug} == 2;
		if (lc($conf->{vm}{$name}{'state'}) eq "started")
		{
			print __LINE__."; [ DEBUG ] - Already running on: [$conf->{vm}{$name}{host}], skipping.\n" if $conf->{debug} == 2;
			print "   - Already running on: [$conf->{vm}{$name}{host}].\n" if $conf->{debug} == 1;
			next;
		}
		read_vm_definition($conf, $name, $conf->{vm}{$name}{definition});
		
		my $preferred_node = "";
		my $in_domain      = $conf->{vm}{$name}{domain};
		print __LINE__."; [ DEBUG ] - in_domain: [$in_domain].\n" if $conf->{debug} == 2;
		foreach my $priority (sort {$a cmp $b} keys %{$conf->{failoverdomain}{$in_domain}{priority}})
		{
			print __LINE__."; [ DEBUG ] - failoverdomain::${in_domain}::priority::${priority}::node: [$conf->{failoverdomain}{$in_domain}{priority}{$priority}{node}].\n" if $conf->{debug} == 2;
			$preferred_node = $conf->{failoverdomain}{$in_domain}{priority}{$priority}{node};
			print __LINE__."; [ DEBUG ] - preferred_node: [$preferred_node].\n" if $conf->{debug} == 2;
			last;
		}
		print "   - Preferred node is: [$preferred_node].\n" if $conf->{debug} == 1;
		
		my $preferred_node_is = "me";
		my $backup_node_is    = "peer";
		print __LINE__."; [ DEBUG ] - preferred_node: [$preferred_node], nodes::peer::hostname: [$conf->{nodes}{peer}{hostname}].\n" if $conf->{debug} == 2;
		if ($preferred_node eq $conf->{nodes}{peer}{hostname})
		{
			$preferred_node_is = "peer";
			$backup_node_is    = "me";
		}
		print __LINE__."; [ DEBUG ] - preferred_node_is: [$preferred_node_is], backup_node_is: [$backup_node_is].\n" if $conf->{debug} == 2;
		
		# Make sure I can boot the server on the preferred host.
		my $can_boot_on_preferred = 1;
		my $can_boot_on_backup    = 1;
		print __LINE__."; [ DEBUG ] - nodes::${preferred_node_is}::healthy: [$conf->{nodes}{$preferred_node_is}{healthy}].\n" if $conf->{debug} == 2;
		if ($conf->{nodes}{$preferred_node_is}{healthy} == 1)
		{
			# Loop through each LV attached to this server, determine which
			# PVs are under it and make sure it/they are UpToDate.
			print __LINE__."; [ DEBUG ] - Checking storage health of preferred node: [$preferred_node_is ($conf->{nodes}{$preferred_node_is}{hostname})].\n" if $conf->{debug} == 2;
			foreach my $lv_path (sort {$a cmp $b} @{$conf->{vms}{$name}{lv_path}})
			{
				my $pvs = $conf->{lvs}{$lv_path}{pvs};
				print __LINE__."; [ DEBUG ] - lv_path: [$lv_path], pvs: [$pvs]\n" if $conf->{debug} == 2;
				foreach my $device_path (split/,/, $pvs)
				{
					print __LINE__."; [ DEBUG ] - device_path: [$device_path]\n" if $conf->{debug} == 2;
					my $role       = $conf->{drbd}{$device_path}{$preferred_node_is}{role};
					my $disk_state = $conf->{drbd}{$device_path}{$preferred_node_is}{disk_state};
					print __LINE__."; [ DEBUG ] - preferred_node_is: [$preferred_node_is], role: [$role], disk_state: [$disk_state]\n" if $conf->{debug} == 2;
					if ((lc($role) ne "primary") or (lc($disk_state) ne "uptodate"))
					{
						print __LINE__."; [ DEBUG ] - Can't boot on preferred node.\n" if $conf->{debug} == 2;
						print "   - I can not boot this server on the preferred node, storage isn't ready.\n" if $conf->{debug} == 1;
						$can_boot_on_preferred = 0;
					}
				}
			}
		}
		if (($conf->{nodes}{$backup_node_is}{healthy} == 1) && (not $can_boot_on_preferred))
		{
			# Peer isn't healthy, make sure I am  
			print __LINE__."; [ DEBUG ] - Checking storage health of backup node: [$backup_node_is] ($conf->{nodes}{$backup_node_is}{hostname})].\n" if $conf->{debug} == 2;
			foreach my $lv_path (sort {$a cmp $b} @{$conf->{vms}{$name}{lv_path}})
			{
				my $pvs = $conf->{lvs}{$lv_path}{pvs};
				print __LINE__."; [ DEBUG ] - lv_path: [$lv_path], pvs: [$pvs]\n" if $conf->{debug} == 2;
				foreach my $device_path (split/,/, $pvs)
				{
					print __LINE__."; [ DEBUG ] - device_path: [$device_path]\n" if $conf->{debug} == 2;
					my $role       = $conf->{drbd}{$device_path}{$backup_node_is}{role};
					my $disk_state = $conf->{drbd}{$device_path}{$backup_node_is}{disk_state};
					print __LINE__."; [ DEBUG ] - backup_node_is: [$backup_node_is], role: [$role], disk_state: [$disk_state]\n" if $conf->{debug} == 2;
					if ((lc($role) ne "primary") or (lc($disk_state) ne "uptodate"))
					{
						print __LINE__."; [ DEBUG ] - Can't boot on backup node.\n" if $conf->{debug} == 2;
						print "   - I can not boot this server on the backup node, storage isn't ready.\n" if $conf->{debug} == 1;
						$can_boot_on_backup = 0;
					}
				}
			}
		}
		
		# Ok, start!
		if ((not $can_boot_on_preferred) && (not $can_boot_on_backup))
		{
			print __LINE__."; [ DEBUG ] - Neither node can run the server: [$name]. Skipping it.\n" if $conf->{debug} == 2;
			print "   - Unable to boot this server, skipping it.\n" if $conf->{debug} == 1;
		}
		else
		{
			my $fh = IO::Handle->new();
			my $sc = "$conf->{path}{clusvcadm} -e vm:$name -m $preferred_node";
			if ($can_boot_on_preferred)
			{
				my $preferred_node = $conf->{nodes}{$preferred_node_is}{hostname};
				print __LINE__."; [ DEBUG ] - Starting server: [$name] on the preferred node: [$preferred_node].\n" if $conf->{debug} == 2;
				print "   - Ready to start!\n" if $conf->{debug} == 1;
			}
			elsif ($can_boot_on_backup)
			{
				my $backup_node = $conf->{nodes}{$backup_node_is}{hostname};
				print __LINE__."; [ DEBUG ] - Starting server: [$name] on the backup node: [$backup_node].\n" if $conf->{debug} == 2;
				$sc = "$conf->{path}{clusvcadm} -e vm:$name -m $backup_node";
				print "   - Starting server on backup node.\n" if $conf->{debug} == 1;
			}
			print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
			open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
			while(<$fh>)
			{
				chomp;
				my $line = $_;
				print __LINE__."; [ DEBUG ] - line: [$line].\n" if $conf->{debug} == 2;
			}
			$fh->close();
			print "   - Started!\n" if $conf->{debug} == 1;
		}
	}
	
	return(0);
}

# This checks to see if a file is a symlink or not. If so, it returns the
# target.
sub check_if_symlink
{
	my ($conf, $file, $node) = @_;
	print __LINE__."; [ DEBUG ] - check_if_symlink(); file: [$file], node: [$node]\n" if $conf->{debug} == 2;
	my $target = "";
	
	my $fh = IO::Handle->new();
	my $sc = "$conf->{path}{ls} -l $file";
	if ($node eq "peer")
	{
		$sc = "$conf->{path}{ssh} root\@$conf->{nodes}{peer}{hostname} \"$conf->{path}{ls} -l $file\"";
	}
	print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
	while(<$fh>)
	{
		chomp;
		my $line = $_;
		print __LINE__."; [ DEBUG ] - line: [$line].\n" if $conf->{debug} == 2;
		if ($line =~ /$file\s->\s(.*)/)
		{
			$target = $1;
			print __LINE__."; [ DEBUG ] - target: [$target].\n" if $conf->{debug} == 2;
		}
	}
	$fh->close();
	
	if ($target =~ /^\.\.\//)
	{
		my $path = dirname $file;
		print __LINE__."; [ DEBUG ] - file: [$file], path: [$path], target: [$target].\n" if $conf->{debug} == 2;
		while ($target =~ /^\.\.\//)
		{
			$path   =  dirname $path;
			$target =~ s/^\.\.\///;
			print __LINE__."; [ DEBUG ] - target: [$target], path: [$path].\n" if $conf->{debug} == 2;
		}
		$target =  $path."/".$target;
		$target =~ s/\/\//\//g;
	}
	
	print __LINE__."; [ DEBUG ] - target: [$target].\n" if $conf->{debug} == 2;
	return ($target);
}

# This calls 'clustat' and checks to make sure no services are in a 'failed'
# state.
sub check_clustat
{
	my ($conf) = @_;
	
	my $fh = IO::Handle->new();
	my $sc = "$conf->{path}{clustat}";
	print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
	while(<$fh>)
	{
		chomp;
		my $line = $_;
		$line =~ s/^\s+//;
		$line =~ s/\s+$//;
		$line =~ s/\s+/ /g;
		next if not $line;
		print __LINE__."; [ DEBUG ] - line: [$line].\n" if $conf->{debug} == 2;
		if ($line =~ /service:(.*?)\s(.*?)\s(.*)/)
		{
			my $service = $1;
			my $host    = $2;
			my $state   = $3;
			print __LINE__."; [ DEBUG ] - service: [$service], host: [$host], state: [$state].\n" if $conf->{debug} == 2;
			$conf->{services}{$service}{host}    = $host;
			$conf->{services}{$service}{'state'} = $state;
			print __LINE__."; [ DEBUG ] - service::${service}::host: [$conf->{services}{$service}{host}], service::${service}::state: [$conf->{services}{$service}{state}].\n" if $conf->{debug} == 2;
		}
		if ($line =~ /vm:(.*?)\s(.*?)\s(.*)/)
		{
			my $name  = $1;
			my $host  = $2;
			my $state = $3;
			print __LINE__."; [ DEBUG ] - name: [$name], host: [$host], state: [$state].\n" if $conf->{debug} == 2;

			$conf->{vm}{$name}{host}    = $host;
			$conf->{vm}{$name}{'state'} = $state;
			print __LINE__."; [ DEBUG ] - vm::${name}::host: [$conf->{vm}{$name}{host}], vm::${name}::state: [$conf->{vm}{$name}{'state'}].\n" if $conf->{debug} == 2;
		}
	}
	$fh->close();
	
	return(0);
}

# This calls 'df -P' and parses the output.
sub read_df
{
	my ($conf, $node) = @_;
	print __LINE__."; [ DEBUG ] - read_df(); node: [$node]\n" if $conf->{debug} == 2;
	
	my $fh = IO::Handle->new();
	my $sc = "$conf->{path}{df} -P";
	if ($node eq "peer")
	{
		$sc = "$conf->{path}{ssh} root\@$conf->{nodes}{peer}{hostname} \"$conf->{path}{df} -P\"";
	}
	print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
	while(<$fh>)
	{
		chomp;
		my $line = $_;
		print __LINE__."; [ DEBUG ] - line: [$line].\n" if $conf->{debug} == 2;
		next if ($line !~ /^\//);
		if ($line =~ /^(\/.*?)\s.*?(\/.*)/)
		{
			my $device     = $1;
			my $mountpoint = $2;
			print __LINE__."; [ DEBUG ] - device: [$device], mountpoint: [$mountpoint].\n" if $conf->{debug} == 2;
			$conf->{nodes}{$node}{mounts}{$device} = $mountpoint;
			print __LINE__."; [ DEBUG ] - nodes::${node}::mounts::${device}: [$conf->{nodes}{$node}{mounts}{$device}].\n" if $conf->{debug} == 2;
		}
	}
	$fh->close();
	
	# I need to get the device-mapper name for the mounts, if there is one,
	# as the LVs behind the gfs2 partitions often display in 'df' 
	# differently that is listed in cluster.conf'.
	foreach my $device (sort {$a cmp $b} keys %{$conf->{nodes}{$node}{mounts}})
	{
		my $mountpoint = $conf->{nodes}{$node}{mounts}{$device};
		print __LINE__."; [ DEBUG ] - Checking if: [$device], mounted at: [$mountpoint] is a symlink.\n" if $conf->{debug} == 2;
		my ($target) = check_if_symlink($conf, $device, $node);
		if ($target)
		{
			$conf->{nodes}{$node}{mounts}{$target} = $mountpoint;
			print __LINE__."; [ DEBUG ] - nodes::${node}::mounts::${target}: [$conf->{nodes}{$node}{mounts}{$target}].\n" if $conf->{debug} == 2;
		}
		else
		{
			print __LINE__."; [ DEBUG ] - nodes::${node}::mounts::${device}, mounted at: [$conf->{nodes}{$node}{mounts}{$device}], is _not_ a symlink.\n" if $conf->{debug} == 2;
		}
	}
	
	return(0);
}

# This will wait for a period of time waiting for daemons and the gfs2 
# partition started by rgmanager services to come online. If a daemon is not
# up after the timeout, or goes into a failed state, the node will not be a 
# host candidate for servers.
sub check_node_health
{
	my ($conf) = @_;
	
	print " - Waiting up to: [$conf->{timeouts}{wait_for_node_health}] seconds for the nodes to become healthy.\n" if $conf->{debug} == 1;
	print " - ." if $conf->{debug} == 1;
	print __LINE__."; [ DEBUG ] - timeouts::wait_for_node_health: [$conf->{timeouts}{wait_for_node_health}]\n" if $conf->{debug} == 2;
	for (0..$conf->{timeouts}{wait_for_node_health})
	{
		check_daemons($conf);
		read_df($conf, "me");
		read_df($conf, "peer");
		check_clustat($conf);
		
		$conf->{nodes}{me}{healthy}   = 1;
		$conf->{nodes}{peer}{healthy} = 1;
		foreach my $daemon (sort {$a cmp $b} keys %{$conf->{daemons}})
		{
			print __LINE__."; [ DEBUG ] - daemon: [$daemon]\n" if $conf->{debug} == 2;
			foreach my $node ("me", "peer")
			{
				print __LINE__."; [ DEBUG ] - node: [$node], ${node}::daemon::${daemon}::rc: [$conf->{$node}{daemon}{$daemon}{rc}]\n" if $conf->{debug} == 2;
				if ($conf->{$node}{daemon}{$daemon}{rc} ne "0")
				{
					$conf->{nodes}{$node}{healthy} = 0;
					print __LINE__."; [ DEBUG ] - nodes::${node}::healthy: [$conf->{nodes}{$node}{healthy}]\n" if $conf->{debug} == 2;
					print "." if $conf->{debug} == 1;
				}
			}
		}
		
		foreach my $clusterfs (sort {$a cmp $b} keys %{$conf->{cluster}{gfs2}})
		{
			print __LINE__."; [ DEBUG ] - clusterfs: [$clusterfs]\n" if $conf->{debug} == 2;
			foreach my $node ("me", "peer")
			{
				print __LINE__."; [ DEBUG ] - node: [$node], cluster::gfs2::${clusterfs}::device: [$conf->{cluster}{gfs2}{$clusterfs}{device}], cluster::gfs2::${clusterfs}::mountpoint: [$conf->{cluster}{gfs2}{$clusterfs}{mountpoint}]\n" if $conf->{debug} == 2;
				my $device     = $conf->{cluster}{gfs2}{$clusterfs}{device};
				my $mountpoint = $conf->{cluster}{gfs2}{$clusterfs}{mountpoint};
				print __LINE__."; [ DEBUG ] - device: [$device], mountpoint: [$mountpoint]\n" if $conf->{debug} == 2;
				my ($target) = check_if_symlink($conf, $device, $node);
				if ($target)
				{
					my $old_device = $device;
					$device        = $target;
					$conf->{cluster}{gfs2}{$clusterfs}{device} = $target;
					print __LINE__."; [ DEBUG ] - Adapting device to symlink target; cluster::gfs2::${clusterfs}::device: [$conf->{cluster}{gfs2}{$clusterfs}{device}], was: [$old_device].\n" if $conf->{debug} == 2;
				}
				
				print __LINE__."; [ DEBUG ] - node: [$node], device: [$device].\n" if $conf->{debug} == 2;
				#print __LINE__."; [ DEBUG ] - nodes::${node}::mounts::${device}: [$conf->{nodes}{$node}{mounts}{$device}], cluster::gfs2::${clusterfs}::mountpoint: [$conf->{cluster}{gfs2}{$clusterfs}{mountpoint}].\n" if $conf->{debug} == 2;
				if (not exists $conf->{nodes}{$node}{mounts}{$device})
				{
					print __LINE__."; [ DEBUG ] - nodes::${node}::mounts::${device} not mounted.\n" if $conf->{debug} == 2;
					$conf->{nodes}{$node}{healthy} = 0;
					print "." if $conf->{debug} == 1;
				}
				elsif ($conf->{nodes}{$node}{mounts}{$device} eq $conf->{cluster}{gfs2}{$clusterfs}{mountpoint})
				{
					print __LINE__."; [ DEBUG ] - clusterfs: [$clusterfs] mounted properly: [$conf->{cluster}{gfs2}{$clusterfs}{mountpoint}].\n" if $conf->{debug} == 2;
				}
				else
				{
					print __LINE__."; [ DEBUG ] - Unexpected mount point! nodes::${node}::mounts::${device}: [$conf->{nodes}{$node}{mounts}{$device}], expected: [$conf->{cluster}{gfs2}{$clusterfs}{mountpoint}].\n" if $conf->{debug} == 2;
					$conf->{nodes}{$node}{healthy} = 2;
				}
			}
		}
		foreach my $service (sort {$a cmp $b} keys %{$conf->{services}})
		{
			print __LINE__."; [ DEBUG ] - services::${service}::state: [$conf->{services}{$service}{'state'}], host: [$conf->{services}{$service}{host}], my host name: [$conf->{nodes}{me}{hostname}], peer's host name: [$conf->{nodes}{peer}{hostname}] \n" if $conf->{debug} == 2;
			my $node = $conf->{services}{$service}{host} eq $conf->{nodes}{me}{hostname} ? "me" : "peer";
			if ($conf->{services}{$service}{'state'} eq "failed")
			{
				print __LINE__."; [ DEBUG ] - Service: [$service] on host: [$conf->{services}{$service}{'state'}] is 'failed'. Marking node: [$conf->{nodes}{$node}{hostname} ($node)] as unhealthy.\n" if $conf->{debug} == 2;
				$conf->{nodes}{$node}{healthy} = 2;
			}
			elsif ($conf->{services}{$service}{'state'} eq "started")
			{
				print __LINE__."; [ DEBUG ] - Service: [$service] started on host: [$conf->{services}{$service}{host}].\n" if $conf->{debug} == 2;
			}
			else
			{
				#print __LINE__."; [ DEBUG ] - Service: [$service] is in state: [$conf->{services}{$service}{'state'}].\n" if $conf->{debug} == 2;
				print __LINE__."; [ DEBUG ] - Service: [$service] is in state: [$conf->{services}{$service}{'state'}].\n";
				$conf->{nodes}{$node}{healthy} = 0;
				print "." if $conf->{debug} == 1;
			}
		}
		
		# TODO: Make sure all LVs are 'ACTIVE' and, if not, try to
		#       activate them.
		
		print __LINE__."; [ DEBUG ] - Node health; nodes::me::healthy: [$conf->{nodes}{me}{healthy}], nodes::peer::healthy: [$conf->{nodes}{peer}{healthy}].\n" if $conf->{debug} == 2;
		if (($conf->{nodes}{me}{healthy} == 1) && ($conf->{nodes}{peer}{healthy} == 1))
		{
			print __LINE__."; [ DEBUG ] - Both nodes appear to be healthy now.\n" if $conf->{debug} == 2;
			print " - Both nodes are now healthy.\n" if $conf->{debug} == 1;
			last;
		}
		elsif (($conf->{nodes}{me}{healthy} == 1) && ($conf->{nodes}{peer}{healthy} == 2))
		{
			print __LINE__."; [ DEBUG ] - I am healthy, but my peer is not. Exiting the health check.\n" if $conf->{debug} == 2;
			print " - I am healthy, but my peer is not.\n" if $conf->{debug} == 1;
			last;
		}
		elsif (($conf->{nodes}{me}{healthy} == 2) && ($conf->{nodes}{peer}{healthy} == 1))
		{
			print __LINE__."; [ DEBUG ] - My peer is healthy, but I am not.\n" if $conf->{debug} == 2;
			print __LINE__."; [ DEBUG ] - Exiting. The peer's 'safe_anvil_start' should boot the servers.\n" if $conf->{debug} == 2;
			print " - My peer is healthy, but I am not. Exiting.\n" if $conf->{debug} == 1;
			exit(3);
		}
		elsif (($conf->{nodes}{me}{healthy} == 2) && ($conf->{nodes}{peer}{healthy} == 2))
		{
			print __LINE__."; [ DEBUG ] - Both nodes have critical issues and can not proceed.\n" if $conf->{debug} == 2;
			print "Both nodes are in a failed state. Unable to proceed.\n";
			print " - Both nodes are unhealthy. Exiting.\n" if $conf->{debug} == 1;
			exit(4);
		}
		sleep 1;
	}
	if ($conf->{nodes}{me}{healthy} != 1)
	{
		print __LINE__."; [ DEBUG ] - Hit the timeout waiting for local nodes to become healthy, exiting.\n" if $conf->{debug} == 2;
		print " - Timed out waiting for this node to become healthy, exiting.\n" if $conf->{debug} == 1;
		exit(5);
	}
	elsif ($conf->{nodes}{peer}{healthy} != 1)
	{
		print __LINE__."; [ DEBUG ] - Hit the timeout waiting for my peer to become healthy, proceeding.\n" if $conf->{debug} == 2;
		print " - Timed out waiting for my peer to become healthy, proceeding.\n" if $conf->{debug} == 1;
	}

	return(0);
}

# This will fork in order to start the requested daemon on both nodes at the
# same time.
sub start_daemon_simultaneously
{
	my ($conf, $daemon) = @_;
	print __LINE__."; [ DEBUG ] - start_daemon_simultaneously(); daemon: [$daemon]\n" if $conf->{debug} == 2;
	print " - Starting: [$daemon].\n" if $conf->{debug} == 1;
	
	# I need to fork here because the calls won't return until cman
	# either talks to it's peer or fences it.
	my $parent_pid = $$;
	print __LINE__."; [ DEBUG ($$) ] - Parent PID: [$parent_pid]\n" if $conf->{debug} == 2;
	
	my %pids;
	defined(my $pid = fork) or die "Can't fork(), error was: $!\n";
	if ($pid)
	{
		# Parent
		$pids{$pid} = 1;
		print __LINE__."; [ DEBUG ($$) - Parent ] - Spawned child with PID: [$pid] to start: [$daemon] on: [$conf->{nodes}{me}{hostname}].\n" if $conf->{debug} == 2;
		print __LINE__."; [ DEBUG ($$) - Parent ] - me::daemon::${daemon}::rc: [$conf->{me}{daemon}{$daemon}{rc}].\n" if $conf->{debug} == 2;
		if ($conf->{me}{daemon}{$daemon}{rc} eq "3")
		{
			# Start the daemon locally.
			my $fh = IO::Handle->new();
			my $sc = "$conf->{daemons}{$daemon} start; echo $daemon:\$?";
			print __LINE__."; [ DEBUG ($$) - Parent ] - shell call: [$sc]\n" if $conf->{debug} == 2;
			print "   - Starting locally.\n" if $conf->{debug} == 1;
			open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
			while(<$fh>)
			{
				chomp;
				my $line = $_;
				print __LINE__."; [ DEBUG ($$) - Parent ] - line: [$line].\n" if $conf->{debug} == 2;
			}
			$fh->close();
		}
		elsif ($conf->{me}{daemon}{$daemon}{rc} eq "0")
		{
			print __LINE__."; [ DEBUG ($$) - Parent ] - Daemon: [$daemon] already running locally.\n" if $conf->{debug} == 2;
			print "   - Daemon: [$daemon] is already running locally.\n" if $conf->{debug} == 1;
		}
		print __LINE__."; [ DEBUG ($$) - Parent ] - Parent process: [$pid ($$)] exiting.\n" if $conf->{debug} == 2;
	}
	else
	{
		# Child
		print __LINE__."; [ DEBUG ($$) - Child ] - Child process continuing.\n" if $conf->{debug} == 2;
		print __LINE__."; [ DEBUG ($$) - Child ] - peer::daemon::${daemon}::rc: [$conf->{peer}{daemon}{$daemon}{rc}].\n" if $conf->{debug} == 2;
		if ($conf->{peer}{daemon}{$daemon}{rc} eq "3")
		{
			# Start needed on the peer.
			my $fh = IO::Handle->new();
			my $sc = "$conf->{path}{ssh} root\@$conf->{nodes}{peer}{hostname} \"$conf->{daemons}{$daemon} start; echo $daemon:\\\$?\"";
			print __LINE__."; [ DEBUG ($$) - Child ] - shell call: [$sc]\n" if $conf->{debug} == 2;
			print "   - Starting on peer.\n" if $conf->{debug} == 1;
			open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
			while(<$fh>)
			{
				chomp;
				my $line = $_;
				print __LINE__."; [ DEBUG ($$) - Child ] - line: [$line].\n" if $conf->{debug} == 2;
			}
			$fh->close();
		}
		elsif ($conf->{peer}{daemon}{$daemon}{rc} eq "0")
		{
			print __LINE__."; [ DEBUG ($$) - Child ] - Daemon: [$daemon] already running on: [$conf->{nodes}{peer}{hostname}].\n" if $conf->{debug} == 2;
			print "   - Daemon: [$daemon] is already running on the peer.\n" if $conf->{debug} == 1;
		}
		sleep 1;	# This probably isn't needed.
		print __LINE__."; [ DEBUG ($$) - Child ] - Child process exiting.\n" if $conf->{debug} == 2;
		exit;
	}
	print __LINE__."; [ DEBUG ($$) ] - Done fork()ing.\n" if $conf->{debug} == 2;
	
	# Now loop until both child processes are dead.
	# This helps to catch hung children.
	my $saw_reaped = 0;
	
	# If I am here, then I am the parent process and all the child process have
	# been spawned. I will not enter a while() loop that will exist for however
	# long the %pids hash has data.
	while (%pids)
	{
		# This is a bit of an odd loop that put's the while()
		# at the end. It will cycle once per child-exit event.
		my $pid;
		do
		{
			# 'wait' returns the PID of each child as they
			# exit. Once all children are gone it returns 
			# '-1'.
			$pid = wait;
			if ($pid < 1)
			{
				print __LINE__."; [ DEBUG ($$) ] - Parent process thinks all children are gone now as wait returned: [$pid]. Exiting loop.\n" if $conf->{debug} == 2;
			}
			else
			{
				print __LINE__."; [ DEBUG ($$) ] - Parent process told that child with PID: [$pid] has exited.\n" if $conf->{debug} == 2;
			}
			
			# This deletes the just-exited child process' PID from the
			# %pids hash.
			delete $pids{$pid};
			
			# This counter is a safety mechanism. If I see more PIDs exit
			# than I spawned, something went oddly and I need to bail.
			$saw_reaped++;
			if ($saw_reaped > 2)
			{
				print "All children should be gone now but it seems the program went into an infinit loop.\n";
				exit(3);
			}
		}
		while $pid > 0;	# This re-enters the do() loop for as
				# long as the PID returned by wait()
				# was >0.
	}
	print __LINE__."; [ DEBUG ($$) ] - Done watching child processes.\n" if $conf->{debug} == 2;
	print "   - done!\n" if $conf->{debug} == 1;
	
	if ($daemon eq "rgmanager")
	{
		print __LINE__."; [ DEBUG ] - rgmanager started, sleeping for a minute.\n" if $conf->{debug} == 2;
		sleep 60;
	}
	
	return(0);
}

# This calls 'status' against the daemons found in cluster.conf (plus 'cman' 
# and 'rgmanager') and records their return code for the given node.
sub get_daemon_state
{
	my ($conf, $daemon, $node) = @_;
	print __LINE__."; [ DEBUG ] - get_daemon_state(); daemon: [$daemon], node: [$node]\n" if $conf->{debug} == 2;

	# Return code:
	# 0   == Started
	# 1   == Bad call
	# 3   == Stopped
	# 127 == File not found
	my $fh = IO::Handle->new();
	my $sc = "$conf->{daemons}{$daemon} status; echo $daemon:\$?";
	if ($node eq "peer")
	{
		$sc = "$conf->{path}{ssh} root\@$conf->{nodes}{peer}{hostname} \"$conf->{daemons}{$daemon} status; echo $daemon:\\\$?\"";
	}
	print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
	while(<$fh>)
	{
		chomp;
		my $line = $_;
		if ($line =~ /$daemon:(\d+)/)
		{
			$conf->{$node}{daemon}{$daemon}{rc} = $1;
			print __LINE__."; [ DEBUG ] - ${node}::daemon::${daemon}::rc: [$conf->{$node}{daemon}{$daemon}{rc}]\n" if $conf->{debug} == 2;
		}
		elsif ($line =~ /No such file or directory/)
		{
			print "Unable to find daemon script: [$conf->{daemon}{$daemon}] on: [$conf->{nodes}{$node}{hostname}]\n";
		}
		else
		{
			print __LINE__."; [ DEBUG ] - line: [$line]\n" if $conf->{debug} == 2;
		}
	}
	$fh->close();
	
	if (($conf->{$node}{daemon}{$daemon}{rc} ne "0") && ($conf->{$node}{daemon}{$daemon}{rc} ne "3"))
	{
		if ($node eq "me")
		{
			print "Daemon: [$daemon] is in an unknown state on this node.\n";
		}
		else
		{
			print "Daemon: [$daemon] is in an unknown state on: [$conf->{nodes}{peer}{hostname}].\n";
		}
		print "Status return code was: [$conf->{$node}{daemon}{$daemon}{rc}].\n";
		print "Only '0' (started) and '3' (stopped) are handled.\n";
		exit(2);
	}
	
	return($conf->{$node}{daemon}{$daemon}{rc});
}

# This is a simple wrapper to call get_daemon_state() against both nodes.
sub check_daemons
{
	my ($conf) = @_;
	
	foreach my $daemon (sort {$a cmp $b} keys %{$conf->{daemons}})
	{
		print __LINE__."; [ DEBUG ] - Checking daemon: [$daemon] using: [$conf->{daemons}{$daemon}]\n" if $conf->{debug} == 2;
		get_daemon_state($conf, $daemon, "me");
		get_daemon_state($conf, $daemon, "peer");
	}
	
	return(0);
}

# This simply checks for an ssh-able connectiong to the peer.
sub check_peer_connection
{
	my ($conf) = @_;
	
	if (not $conf->{nodes}{peer}{hostname})
	{
		print "Can't connect to peer, peer host name unknown.\n";
		exit(1);
	}
	
	my $fh = IO::Handle->new();
	my $sc = "$conf->{path}{ssh} root\@$conf->{nodes}{peer}{hostname} \"$conf->{path}{echo} 1\"";
	print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
	while(<$fh>)
	{
		# I don't care about this output
		chomp;
		my $line = $_;
		if ($line eq "1")
		{
			$conf->{nodes}{peer}{reachable} = 1; 
			print __LINE__."; [ DEBUG ] - nodes::peer_reachable: [$conf->{nodes}{peer}{reachable}]\n" if $conf->{debug} == 2;
		}
		else
		{
			print __LINE__."; [ DEBUG ] - line: [$line]\n" if $conf->{debug} == 2;
		}
	}
	$fh->close();
	
	return($conf->{nodes}{peer}{reachable});
}

# Read the cluster configuration file. This forms the backbone of all that
# we'll do next.
sub read_cluster_conf
{
	my ($conf) = @_;
	
	my $in_domain = "";
	my $fh = IO::Handle->new();
	my $sc = "$conf->{path}{cluster_conf}";
	print " - Reading the cluster configuration.\n" if $conf->{debug} == 1;
	print __LINE__."; [ DEBUG ] - File read: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "<$sc") or die "Failed to read: [$sc], error was: $!\n";
	while(<$fh>)
	{
		# I don't care about this output
		chomp;
		my $line = $_;
		print __LINE__."; [ DEBUG ] - line: [$line]\n" if $conf->{debug} == 2;
		
		# Pull out the cluster name. This has no use yet, beyond
		# telling the user.
		if ($line =~ /<cluster .*?name="(.*?)"/)
		{
			$conf->{cluster}{name} = $1;
			print __LINE__."; [ DEBUG ] - cluster::name: [$conf->{cluster}{name}]\n" if $conf->{debug} == 2;
			print " - This cluster is called: [$conf->{cluster}{name}].\n" if $conf->{debug} == 1;
			next;
		}
		
		# One of these has to match the hostname and the other must be
		# usable to log into the peer.
		if ($line =~ /<clusternode .*?name="(.*?)"/)
		{
			my $node = $1;
			if ($node ne $conf->{nodes}{me}{hostname})
			{
				# Shorten the names and see if they match.
				print __LINE__."; [ DEBUG ] - nodes::me::hostname: [$conf->{nodes}{me}{hostname}], node: [$node]\n" if $conf->{debug} == 2;
				my ($short_hostname) = ($conf->{nodes}{me}{hostname} =~ /^(.*?)\./);
				my ($short_nodename) = ($node                        =~ /^(.*?)\./);
				print __LINE__."; [ DEBUG ] - short_hostname: [$short_hostname], short_nodename: [$short_nodename]\n" if $conf->{debug} == 2;
				if ($short_hostname ne $short_nodename)
				{
					$conf->{nodes}{peer}{hostname}   = $node;
					$conf->{nodes}{peer}{short_name} = $short_nodename;
					$conf->{nodes}{me}{short_name}   = $short_hostname;
					print __LINE__."; [ DEBUG ] - nodes::peer::hostname: [$conf->{nodes}{peer}{hostname}], nodes::peer::short_name: [$conf->{nodes}{peer}{short_name}], nodes::me::short_name: [$conf->{nodes}{me}{short_name}]\n" if $conf->{debug} == 2;
					print " - This peer's host name is: [$conf->{nodes}{peer}{hostname}].\n" if $conf->{debug} == 1;
				}
			}
			next;
		}
		
		# The scripts I find here will be the daemons whose status I
		# will check later to determine health.
		# TODO: If a script service is defined but not in a service,
		#       this script will fail.
		if ($line =~ /<script file="(.*?)"/)
		{
			my $script_path = $1;
			my ($script_name) = ($script_path =~ /.*?\/(\w+)$/);
			#print __LINE__."; [ DEBUG ] - script_path: [$script_path], script_name: [$script_name]\n" if $conf->{debug} == 2;
			$conf->{daemons}{$script_name} = $script_path;
			print __LINE__."; [ DEBUG ] - daemons::$script_name: [$conf->{daemons}{$script_name}]\n" if $conf->{debug} == 2;
			#print " - Found a managed script service called: [$script_name].\n" if $conf->{debug} == 1;
			next;
		}
		
		# Any clusterfs will be checked to make sure they mounted
		# properly. If the 'device' is a symlink to a device mapper
		# device, it will resolve fine as the devices found by 'df'
		# will also be checked for symlinks and resolve to their
		# device mapper device as well.
		if (($line =~ /<clusterfs /) && ($line =~ /device=/))
		{
			my ($device)     = ($line =~ /device="(.*?)"/);
			my ($mountpoint) = ($line =~ /mountpoint="(.*?)"/);
			my ($clusterfs)  = ($line =~ /name="(.*?)"/);
			$conf->{cluster}{gfs2}{$clusterfs}{device}     = $device;
			$conf->{cluster}{gfs2}{$clusterfs}{mountpoint} = $mountpoint,
			print __LINE__."; [ DEBUG ] - cluster::gfs2::${clusterfs}::device: [$conf->{cluster}{gfs2}{$clusterfs}{device}], cluster::gfs2::${clusterfs}::mountpoint: [$conf->{cluster}{gfs2}{$clusterfs}{mountpoint}]\n" if $conf->{debug} == 2;
			#print " - Found a clustered file system called: [$clusterfs] which mounts at: [$conf->{cluster}{gfs2}{$clusterfs}{mountpoint}].\n" if $conf->{debug} == 1;
			next;
		}
		
		# Read the server details. The listed failover domain will be
		# compared against the preferred nodes in the domain to find
		# the preferred host.
		if ($line =~ /<vm /)
		{
			#<vm domain="primary_n01" name="vm07-rhel6"
			my ($name)       =  ($line =~ / name="(.*?)"/);
			my ($domain)     =  ($line =~ / domain="(.*?)"/);
			my ($definition) =  ($line =~ / path="(.*?)"/);
			$definition      .= "/${name}.xml";
			$definition      =~ s/\/\//\//g;
			$conf->{vm}{$name}{domain}     = $domain;
			$conf->{vm}{$name}{definition} = $definition;
			print __LINE__."; [ DEBUG ] - vm::${name}::domain: [$conf->{vm}{$name}{domain}], vm::${name}::definition: [$conf->{vm}{$name}{definition}]\n" if $conf->{debug} == 2;
			print " - Found a server named: [$name] in the failover domain: [$conf->{vm}{$name}{domain}].\n" if $conf->{debug} == 1;
			next;
		}
		
		# This parses the failover domains in a manner that retains
		# their set priority ordering.
		if ($line =~ /<failoverdomain .*?name="(.*?)"/)
		{
			$in_domain = $1;
			print __LINE__."; [ DEBUG ] - in_domain: [$in_domain]\n" if $conf->{debug} == 2;
			#print " - Found the failover domain named: [$in_domain].\n" if $conf->{debug} == 1;
			next;
		}
		if ($in_domain)
		{
			if ($line =~ /<\/failoverdomain>/)
			{
				$in_domain = "";
				print __LINE__."; [ DEBUG ] - Exiting domain; in_domain: [$in_domain]\n" if $conf->{debug} == 2;
				next;
			}
			else
			{
				if ($line =~ /<failoverdomainnode /)
				{
					my ($node)     = ($line =~ / name="(.*?)"/);
					my ($priority) = ($line =~ / priority="(.*?)"/);
					   $priority   = 1 if not $priority;
					$conf->{failoverdomain}{$in_domain}{priority}{$priority}{node} = $node;
					print __LINE__."; [ DEBUG ] - failoverdomain::${in_domain}::priority::${priority}::node: [$conf->{failoverdomain}{$in_domain}{priority}{$priority}{node}]\n" if $conf->{debug} == 2;
					#print "   - Node named: [$node] has priority: [$priority].\n" if $conf->{debug} == 1;
					next;
				}
			}
		}
		
	}
	$fh->close();
	
	return(0);
}

# Read the hostname. This is used shortly to tell which cluster node I am and
# which my peer is.
sub read_hostname
{
	my ($conf) = @_;
	
	my $fh = IO::Handle->new();
	my $sc = "$conf->{path}{hostname}";
	print __LINE__."; [ DEBUG ] - shell call: [$sc]\n" if $conf->{debug} == 2;
	open ($fh, "$sc 2>&1 |") or die "Failed to call: [$sc], error was: $!\n";
	while(<$fh>)
	{
		# I don't care about this output
		chomp;
		$conf->{nodes}{me}{hostname} = $_;
		print __LINE__."; [ DEBUG ] - nodes::me::hostname: [$conf->{nodes}{me}{hostname}]\n" if $conf->{debug} == 2;
		print " - My hostname is: [$conf->{nodes}{me}{hostname}]\n" if $conf->{debug} == 1;
	}
	$fh->close();
	
	# If I am node 02, sleep for 1 minutes to help avoid conflicting with
	# the startup being performed by node 1.
	if ($conf->{nodes}{me}{hostname} =~ /n02/)
	{
		print " - I am not node 1, so I will sleep for a minute.\n" if $conf->{debug} == 1;
		sleep 60;
	}
	
	return($conf->{nodes}{me}{hostname});
}
